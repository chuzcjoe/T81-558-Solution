{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_Yourname_class5.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWgTs5lrPuP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import base64\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import requests\n",
        "\n",
        "# This function submits an assignment.  You can submit an assignment as much as you like, only the final\n",
        "# submission counts.  The paramaters are as follows:\n",
        "# data - Pandas dataframe output.\n",
        "# key - Your student key that was emailed to you.\n",
        "# no - The assignment class number, should be 1 through 1.\n",
        "# source_file - The full path to your Python or IPYNB file.  This must have \"_class1\" as part of its name.  \n",
        "# .             The number must match your assignment number.  For example \"_class2\" for class assignment #2.\n",
        "def submit(data,key,no,source_file=None):\n",
        "    if source_file is None and '__file__' not in globals(): raise Exception('Must specify a filename when a Jupyter notebook.')\n",
        "    if source_file is None: source_file = __file__\n",
        "    suffix = '_class{}'.format(no)\n",
        "    if suffix not in source_file: raise Exception('{} must be part of the filename.'.format(suffix))\n",
        "    with open(source_file, \"rb\") as image_file:\n",
        "        encoded_python = base64.b64encode(image_file.read()).decode('ascii')\n",
        "    ext = os.path.splitext(source_file)[-1].lower()\n",
        "    if ext not in ['.ipynb','.py']: raise Exception(\"Source file is {} must be .py or .ipynb\".format(ext))\n",
        "    r = requests.post(\"https://api.heatonresearch.com/assignment-submit\",\n",
        "        headers={'x-api-key':key}, json={'csv':base64.b64encode(data.to_csv(index=False).encode('ascii')).decode(\"ascii\"),\n",
        "        'assignment': no, 'ext':ext, 'py':encoded_python})\n",
        "    if r.status_code == 200:\n",
        "        print(\"Success: {}\".format(r.text))\n",
        "    else: print(\"Failure: {}\".format(r.text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u02CiaT-Qrwz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from scipy.stats import zscore\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from scipy.stats import zscore\n",
        "\n",
        "# This is your student key that I emailed to you at the beginnning of the semester.\n",
        "key = \"zxSDPsLAb39xNBkgUJ9n58F5bhE5cIlG90IJzIhI\"  # This is an example key and will not work.\n",
        "\n",
        "# You must also identify your source file.  (modify for your local setup)\n",
        "# file='/resources/t81_558_deep_learning/assignment_yourname_class1.ipynb'  # IBM Data Science Workbench\n",
        "# file='C:\\\\Users\\\\jeffh\\\\projects\\\\t81_558_deep_learning\\\\t81_558_class1_intro_python.ipynb'  # Windows\n",
        "#file='/Users/jheaton/projects/t81_558_deep_learning/assignments/assignment_yourname_class5.ipynb'  # Mac/Linux\n",
        "# file = \"C:\\\\Users\\\\jeffh\\\\Dropbox\\\\school\\\\teaching\\\\wustl\\\\classes\\\\T81_558_deep_learning\\\\solutions\\\\assignment_solution_class5.ipynb\"\n",
        "\n",
        "# Begin assignment\n",
        "df = pd.read_csv(\"reg-33-data.csv\")\n",
        "\n",
        "# Encode the feature vector\n",
        "ids = df['id']\n",
        "df.drop('id',1,inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0X2W6IBRD_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Y08qjhXOYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqKDz4RFai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "numerical_cols = ['height','max','number','length','power','weight']\n",
        "text_cols = ['convention','cat2','usage','region','code','item','country']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwxGa4WxRxNY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#fill nan with mean vlaue\n",
        "for column in list(df.columns[df.isnull().sum() > 0]):\n",
        "    mean_val = df[column].mean()\n",
        "    df[column].fillna(mean_val, inplace=True)\n",
        "df.isnull().sum()>0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dC5p6E96SMOJ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgXhrNCERzSe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#normalize\n",
        "for col in numerical_cols:\n",
        "    df.loc[:,col] = zscore(df[col].values)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mpNqEmWUSkU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for col in text_cols:\n",
        "    #print(col)\n",
        "    df = df.join(pd.get_dummies(df[col],prefix=col))\n",
        "new_df = df.drop(columns=text_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heONXjQIXBAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0zSnMHvY5K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = new_df[[x for x in list(new_df.columns) if x != 'target']].values\n",
        "test = new_df['target'].values\n",
        "\n",
        "print(train.shape, test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osfjotexchut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.optimizers import Adadelta\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "\n",
        "def model():\n",
        "    model=Sequential()\n",
        "    model.add(Dense(1000, activation='relu', input_dim=256))\n",
        "    model.add(Dense(1000, activation='relu'))\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(Dense(32, activation='relu'))\n",
        "    model.add(Dense(16, activation='relu'))\n",
        "    model.add(Dense(1))\n",
        "    adam = Adam(learning_rate=0.005, beta_1=0.9, beta_2=0.999, amsgrad=True)\n",
        "    ada = Adadelta(learning_rate=0.002, rho=0.9)\n",
        "    sgd = SGD(lr=0.002, decay=1e-3, momentum=0.9, nesterov=True)\n",
        "    model.compile(loss='mse', optimizer=adam)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36r4IRsIdS5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "model1 = model()\n",
        "    \n",
        "\n",
        "kf = KFold(n_splits=5)\n",
        "kf.get_n_splits(train)\n",
        "cnt = 1\n",
        "\n",
        "for train_index, test_index in kf.split(train):\n",
        "    X_train, X_test = train[train_index], train[test_index]\n",
        "    y_train, y_test = test[train_index], test[test_index]\n",
        "    if cnt == 1:\n",
        "        model1.fit(X_train, y_train, batch_size=128, epochs=100, verbose=0)\n",
        "        model1.evaluate(X_test, y_test, verbose=1)\n",
        "        cnt += 1\n",
        "    elif cnt == 2:\n",
        "        model1.fit(X_train, y_train, batch_size=128, epochs=100, verbose=0)\n",
        "        model1.evaluate(X_test, y_test, verbose=1)\n",
        "        cnt += 1\n",
        "    elif cnt == 3:\n",
        "        model1.fit(X_train, y_train, batch_size=128, epochs=100, verbose=0)\n",
        "        model1.evaluate(X_test, y_test, verbose=1)\n",
        "        cnt += 1\n",
        "    elif cnt == 4:\n",
        "        model1.fit(X_train, y_train, batch_size=128, epochs=100, verbose=0)\n",
        "        model1.evaluate(X_test, y_test, verbose=1)\n",
        "        cnt += 1\n",
        "    else:\n",
        "        model1.fit(X_train, y_train, batch_size=128, epochs=100, verbose=0)\n",
        "        model1.evaluate(X_test, y_test, verbose=1)\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8vChEYbHVmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model2.predict(train)\n",
        "np.sqrt(((predictions - test) ** 2).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVqrMBPjMutU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = model()\n",
        "model2.fit(train, test, batch_size=1024, epochs=1000, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xi0yitVztjn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df = ids.to_frame()\n",
        "new_df['y'] = df['target']\n",
        "new_df['pred'] = pd.Series(predictions.reshape(-1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tI5LD0b50Eir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df['diff'] = new_df['y'] - new_df['pred']\n",
        "new_df['diff'] = new_df['diff'].apply(lambda x: abs(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkAk6yWG0xRA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62pf6BzM2gWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}